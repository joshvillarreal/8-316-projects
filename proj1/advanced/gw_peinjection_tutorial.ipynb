{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Project: GW injection and Parameter estimationÂ¶\n",
    "Author: Tri Nguyen\n",
    "\n",
    "In this tutorial, we will inject a gravitational-wave (GW) signal into LIGO data and perform parameter-estimation (PE) on a redudced parameter space to extract the parameters of the signal. We will be utilizing the Bilby, which is a Python-based user-friendly Bayesian inference library for GW data analysis. For more information about Bilby and how to download it, please visit: https://lscsoft.docs.ligo.org/bilby/ and https://arxiv.org/pdf/1811.02042.pdf. \n",
    "\n",
    "\n",
    "This notebook is based on the Bilby tutorial for GW injection and parameter estimation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Bilby and some of its dependencies\n",
    "!pip install bilby\n",
    "!pip install gwpy lalsuite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "\n",
    "import numpy as np\n",
    "import scipy.signal as sig\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import bilby\n",
    "from bilby.gw.source import lal_binary_black_hole\n",
    "from bilby.gw.conversion import convert_to_lal_binary_black_hole_parameters\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Gravitational-wave injection\n",
    "### Example\n",
    "\n",
    "In the example, we will inject a binary black hole (BBH) into a Gaussian noise background."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(74656541)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Fix the rest\n",
    "# Fix the rest\n",
    "# We are going to inject a binary black hole waveform.  We first establish a\n",
    "# dictionary of parameters that includes all of the different waveform\n",
    "# parameters, including masses of the two black holes (mass_1, mass_2),\n",
    "# spins of both black holes (a, tilt, phi), etc.\n",
    "# make up some injection parameters and inject signal into data\n",
    "injection_parameters = dict(\n",
    "    mass_1=50, mass_2=50, a_1=0., a_2=0., tilt_1=0., tilt_2=0.,\n",
    "    phi_12=0., phi_jl=0., luminosity_distance=500, theta_jn=0., psi=0.,\n",
    "    phase=0.2, geocent_time=1243309096, ra=0., dec=0.)\n",
    "\n",
    "\n",
    "\n",
    "# First, we define the duration and sampling frequency of the data segment\n",
    "# that we will inject the GW signal into. For our BBH, a duration of 4 seconds \n",
    "# will be sufficient to capture the entire waveform.\n",
    "duration = 4.\n",
    "# We set the sampling frequency to 2048 Hz because the BBH waveform does not usually\n",
    "# extend pass 1024 Hz \n",
    "sampling_frequency = 2048."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# LIGO approximates GW waveforms by interpolating between GW templates in a template bank\n",
    "# which is generated from physical simulations (e.g. numerical relativity, post-Newtonian). \n",
    "# These waveform families are called **waveform approximant**. \n",
    "# For more information on these waveform approximants, please visit: \n",
    "\n",
    "# https://www.lsc-group.phys.uwm.edu/ligovirgo/cbcnote/Waveforms/Overview\n",
    "\n",
    "# In this example, we will use the waveform approximant `IMRPhenomPv2`. \n",
    "# This is a phenomenological model that approximates the GW waveforms \n",
    "# during the three stages of an inspiral (Inspiral, Merger, Ringdown). `IMRPhenomPv2` also uses \n",
    "# a single-spin frequency-dependent post-Newtonian rotation  to describe spin precession effects.\n",
    "\n",
    "# We define a WaveformGenerator object to generate any BBH waveform \n",
    "# given the appropriate parameters\n",
    "waveform_arguments = {\n",
    "    'waveform_approximant': 'IMRPhenomPv2',\n",
    "    'reference_frequency': 50.,  # most sensitive frequency\n",
    "    'minimum_frequency': 20.\n",
    "}\n",
    "waveform_generator = bilby.gw.WaveformGenerator(\n",
    "    duration=duration, sampling_frequency=sampling_frequency,\n",
    "    parameter_conversion=convert_to_lal_binary_black_hole_parameters,\n",
    "    frequency_domain_source_model=lal_binary_black_hole,\n",
    "    waveform_arguments=waveform_arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# We'd like to see what kind of signal we will be generating\n",
    "# We examine the signal in the time domain\n",
    "polarizations_td = waveform_generator.time_domain_strain(injection_parameters)\n",
    "plus_td = np.roll(polarizations_td['plus'], int(sampling_frequency * 2))\n",
    "cross_td = np.roll(polarizations_td['cross'], int(sampling_frequency * 2))\n",
    "time = np.linspace(0., duration, len(plus_td))\n",
    "\n",
    "fig = plt.figure(figsize=(8, 5))\n",
    "\n",
    "plt.plot(time, plus_td, label='Plus')\n",
    "plt.plot(time, cross_td, label='Cross')\n",
    "plt.xlabel('Time [sec]')\n",
    "plt.ylabel('Strain')\n",
    "plt.xlim(1.8, 2.02)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# And their ASD\n",
    "NFFT = int(4 * sampling_frequency)\n",
    "freq, plus_psd = sig.welch(plus_td, fs=sampling_frequency, nperseg=NFFT)\n",
    "plus_asd = np.sqrt(plus_psd)\n",
    "\n",
    "freq, cross_psd = sig.welch(cross_td, fs=sampling_frequency, nperseg=NFFT)\n",
    "cross_asd = np.sqrt(cross_psd)\n",
    "\n",
    "fig = plt.figure(figsize=(8, 5))\n",
    "plt.loglog(freq, plus_asd, label='Plus')\n",
    "plt.loglog(freq, cross_asd, label='Cross')\n",
    "plt.xlim(10, 1024)\n",
    "plt.xlabel('Frequency [Hz]')\n",
    "plt.ylabel('ASD')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# For this object, we will only use LIGO Hanford (H1) and LIGO Livingston (L1)\n",
    "# Because H1 and L1 have different antenna patterns (which is based on their \n",
    "# orientation and location of Earth), each will see a different GW waveform. \n",
    "# We set up Bilby Interferometer object with the GPS time around the geocenter time\n",
    "# of the GW signal. By default, each interferometer will have a Gaussian noise \n",
    "# background with the PSD being their design sensitivity.\n",
    "ifos = bilby.gw.detector.InterferometerList(['H1', 'L1'])\n",
    "ifos.set_strain_data_from_power_spectral_densities(\n",
    "    sampling_frequency=sampling_frequency, duration=duration,\n",
    "    start_time=injection_parameters['geocent_time'] - 3)\n",
    "\n",
    "# Inject GW signal into H1 and L1\n",
    "polarizations = ifos.inject_signal(waveform_generator=waveform_generator,\n",
    "                                   parameters=injection_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# We would like to visualize what the injected GW strain looks like\n",
    "# First, we extract the H1 and L1 strain from the Inteferometer object\n",
    "H1_strain = ifos[0].time_domain_strain\n",
    "L1_strain = ifos[1].time_domain_strain\n",
    "\n",
    "# And calculate their PSD and ASD\n",
    "NFFT = int(sampling_frequency * 4)\n",
    "freq, H1_strain_psd = sig.welch(H1_strain, fs=sampling_frequency, nperseg=NFFT)\n",
    "H1_strain_asd = np.sqrt(H1_strain_psd)\n",
    "freq, L1_strain_psd = sig.welch(L1_strain, fs=sampling_frequency, nperseg=NFFT)\n",
    "L1_strain_asd = np.sqrt(L1_strain_psd)\n",
    "\n",
    "# We also like to extract the background PSD and ASD\n",
    "H1_bg_psd = ifos[0].power_spectral_density.psd_array\n",
    "H1_bg_asd = np.sqrt(H1_bg_psd)\n",
    "L1_bg_psd = ifos[1].power_spectral_density.psd_array\n",
    "L1_bg_asd = np.sqrt(L1_bg_psd)\n",
    "freq_bg = ifos[0].power_spectral_density.frequency_array\n",
    "\n",
    "# We plot the strain ASD on top of the background ASD\n",
    "# Because we inject a loud signal (H1 optimal SNR = 73.24, L1 optimal SNR = 79.75)\n",
    "# we should be able to see the signal\n",
    "fig = plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Plot H1 strain and background ASD\n",
    "ax1 = plt.subplot(121)\n",
    "ax1.loglog(freq, H1_strain_asd, label='Strain ASD')\n",
    "ax1.loglog(freq_bg, H1_bg_asd, label='Background ASD')\n",
    "ax1.set_title('H1')\n",
    "ax1.set_xlim(20, 1024)\n",
    "ax1.set_ylim(1e-26, None)\n",
    "ax1.set_xlabel('Frequency')\n",
    "ax1.set_ylabel('ASD')\n",
    "ax1.legend()\n",
    "\n",
    "# Plot L1 strain and background ASD\n",
    "ax2 = plt.subplot(122)\n",
    "ax2.loglog(freq, L1_strain_asd, label='Strain ASD')\n",
    "ax2.loglog(freq_bg, L1_bg_asd, label='Background ASD')\n",
    "ax2.set_title('L1')\n",
    "ax2.set_xlim(20, 1024)\n",
    "ax2.set_ylim(1e-26, None)\n",
    "ax2.set_xlabel('Frequency')\n",
    "ax2.set_ylabel('ASD')\n",
    "ax2.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Student work\n",
    "\n",
    "Now it is your time to shine. Inject a BBH with the following parameters into a Gaussian noise background:\n",
    "\n",
    "- Masses $M_1$ and $M_2$: 36 $M_\\odot$ and 29 $M_\\odot$\n",
    "- Dimensionless spin magnitudes $a_1$ and $a_2$: 0.4 and 0.3\n",
    "- Difference between the azimuthal angles of the individual spin vector projections onto the orbital plane $\\phi_{12}$: 97.4 $\\deg$\n",
    "- Difference between total and orbital angular momentum azimuthal angles $\\phi_{jl}$: 17.2 $\\deg$\n",
    "- Tilt angle between their spins and the orbital angular momentum $\\theta_1$ and $\\theta_2$: 28.6 $\\deg$ and 57.3 $\\deg$\n",
    "- Luminosity distance $D_L$: 2000 Mpc\n",
    "- Inclination angle: $\\theta_{jn}$: 22.9 $\\deg$\n",
    "- Polarisation angle $\\psi$: 152.3 $\\deg$\n",
    "- Phase at coalescence $\\phi_c$: 74.5 $\\deg$\n",
    "- Sky position RA and DEC: 78.8 $\\deg$ and -69.4$\\deg$\n",
    "- Geocentric time: GPS 1126259642.413\n",
    "\n",
    "You should use the same signal duration, sampling frequency, and waveform approximant as above. You do **not** have to reproduce the plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "\n",
    "import numpy as np\n",
    "import scipy.signal as sig\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import bilby\n",
    "from bilby.gw.source import lal_binary_black_hole\n",
    "from bilby.gw.conversion import convert_to_lal_binary_black_hole_parameters\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(74656541)\n",
    "\n",
    "### -------------------START-CODE-------------------- ###\n",
    "\n",
    "### -------------------END-CODE---------------------- ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Parameter estimation\n",
    "\n",
    "We are now ready to extract the parameters of this GW signal from the Gaussian noise background. Our goal is to find the posterior distribution. However, because the posterior distribution is often intractable, LIGO uses posterior sampling algorithm (such as MCMC and Nested Sampling) to evaluate the posterior distribution. We will cover MCMC later in the course.\n",
    "\n",
    "### Example: Gaussian likelihood\n",
    "\n",
    "Let's first get familiar with Bilby posterior sampling API with a simple non-gravitational wave example. In this example, you will estimate the mean and variance of a Gaussian. We will first generate $N$ data $x_i$ sampled from a Gaussian distribtion with mean $\\mu$ and standard devitation $\\sigma$  (i.e. $x \\sim \\mathcal{N}(\\mu, \\sigma^2)$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we'd like to generate some data\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(8596748)\n",
    "\n",
    "# Define the true parameters of the Gaussian distribution\n",
    "N = 100 # number of data points\n",
    "true_mu, true_sigma = 3, 4\n",
    "example_data = np.random.normal(true_mu, true_sigma, size=N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin sampling the posterior distribution, we need to define a prior distribution and a likelihood distribution (Remember Bayes' rule). We will define a Uniform prior for $\\mu$ and $\\sigma$ and Gaussian likelihood. \n",
    "\n",
    "We first set up the prior distribution. Bilby uses `bilby.prior.PriorDict` class structure, which inherits from a Python dictionary, to store the prior of each parameter. For each parameter, its prior can be defined using a Bilby class object (more informatio here: https://lscsoft.docs.ligo.org/bilby/prior.html). For this example, please create a prior dictionary with two keys `mu` and `sigma`. Set `mu` to ${\\mathcal {U}}(0, 5)$ and `sigma` to ${\\mathcal {U}}(0, 10)$, where $\\mathcal{U}$ here denotes the continuous Uniform distribution. You might find the following Bilby class useful `bilby.prior.Uniform`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define PriorDict object\n",
    "priors = bilby.prior.PriorDict()\n",
    "\n",
    "### -------------------START-CODE-------------------- ###\n",
    "\n",
    "priors['mu'] = None\n",
    "priors['sigma'] = None\n",
    "\n",
    "### -------------------END-CODE---------------------- ###\n",
    "\n",
    "priors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now set up the Gaussian likelihood. For $N$ data point $x_i$, the Gaussian likelihood is given as:\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathcal{L}(\\mu, \\sigma | x) = \\frac{1}{(2\\pi\\sigma^2)^{N/2}} \\prod_{i=1}^{N} \\exp\\left(-\\frac{1}{2}\\frac{(x_i - \\mu)^2}{\\sigma^2}\\right)\\\\\n",
    "\\end{equation}\n",
    "\n",
    "In practice, we tend to use the **log likelihood** instead of the likelihood to avoid computation of the exponential (which is annoying analytically and can also cause numerical instability. In this example, we will use the `bilby.Likelihood` class object to keep track of the log likelihood. The `log_likelihood` method is not yet implemented and is patiently waiting for you to finish it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a bilby.Likelihood class object\n",
    "class SimpleGaussianLikelihood(bilby.Likelihood):\n",
    "    def __init__(self, data):\n",
    "        \"\"\"\n",
    "        A very simple Gaussian likelihood\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        data: array_like\n",
    "            The data to analyse\n",
    "        \"\"\"\n",
    "        super().__init__(parameters={'mu': None, 'sigma': None})\n",
    "        self.data = data\n",
    "        self.N = len(data)\n",
    "\n",
    "### -------------------START-CODE-------------------- ###\n",
    "    # Return the log likelihood given parameters. This method \n",
    "    # does NOT take in any argument, instead the parameters \n",
    "    # have to be stored in `self.parameters` attribute\n",
    "    def log_likelihood(self):\n",
    "        mu = self.parameters['mu']\n",
    "        sigma = self.parameters['sigma']        \n",
    "        return \n",
    "### -------------------END-CODE---------------------- ###\n",
    "\n",
    "likelihood = SimpleGaussianLikelihood(example_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we define the prior and likelihood distribution, we can use Bilby to sample the posterior. Bilby is a wrapper to external samplers:\n",
    "\n",
    "- MCMC: emcee, pymc3, ptemcee\n",
    "- Nested sampling: pynesty, pymultinest, nestle, cpnest\n",
    "\n",
    "For this project, we will use `dynesty`, which is a dynamic nested sampling algorithm Python package for estimating Bayesian posteriors and evidences. You can learn more about `dynesty` at https://dynesty.readthedocs.io/en/latest/ and https://arxiv.org/abs/1904.02180."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = bilby.run_sampler(\n",
    "    likelihood=likelihood, priors=priors, sampler='dynesty', npoints=500,\n",
    "    walks=10, outdir='GW_PEInjection_result', label='GaussianExample')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratualations! You have just finished your first posterior distribution sampling. Now, let's show your sampling result by making a beautiful plot. The most common way to show a multi-dimensional posterior distribution is to use a corner plot. Plotting a corner plot manually can be tricky, so we strongly recommend you to use the `corner` package (https://corner.readthedocs.io/en/latest/). However, feel free to use any plotting tool you are accustomed to.\n",
    "\n",
    "What are the final values for $\\mu$ and $\\sigma$ (including error bars)? Are they consistent with the values you get if you were to do this analytically?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we want to extract the posterior samples from bilby.result\n",
    "samples = result.posterior[['mu', 'sigma']].values\n",
    "\n",
    "### -------------------START-CODE-------------------- ###\n",
    "\n",
    "### -------------------END-CODE---------------------- ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer:\n",
    "The final values of $\\mu$ and $\\sigma$ are:\n",
    "\\begin{equation}\n",
    "\\mu = \\;\\text{and}\\; \\sigma = \n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-D parameter estimation on injected GW data\n",
    "\n",
    "Now that you are a bit familiar with Bilby posterior sampling API, let's move on to estimating the parameters of the GW signal you previously created. The steps are similar:\n",
    "\n",
    "1. Define a prior dictionary\n",
    "2. Define a likelihood class\n",
    "3. Run the sampling algorithm\n",
    "4. Plot your result\n",
    "\n",
    "We will first start by defining the prior for all of our 15 GW parameters. LIGO uses a more complex set of priors, with many different types of distribution (not just Uniform distribution) depending on the parameters. For example, angular parameters usually follow a Sine or Cosine distribution. Luminosity distance usually follows a Power law or a cosmology-dependent uniform distribution. Below is an example prior used to extract the parameters of the first BBH GW150914.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_priors = bilby.gw.prior.BBHPriorDict(filename='GW150914.prior')\n",
    "example_priors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Sampling 15 parameters can take up to several days, so we will work with a 2-D space instead. In this example, you will sample the chirp mass $M_c$ and mass ratio $q$ of the BBH, while keeping all other parameters constant (NOTE: this is **not** the same with marginalizing over all other parameters. Why is that?). Similarly as above, define a `bilby.prior.PriorDict()` object and set each parameter to the corresponding Bilby class. Feel free to play around with different type of priors.\n",
    "\n",
    "You might find these Bilby classes useful:\n",
    "- `bilby.prior.Uniform`\n",
    "- `bilby.prior.Gaussian`\n",
    "- `bilby.prior.DeltaFunction`\n",
    "\n",
    "NOTE 1: We usually sample the chirp mass and mass ratio instead of the component masses $M_{1,2}$ because they tend to help the sampler converge faster and more easily. \n",
    "\n",
    "NOTE 2: You will have to define priors for the parameters that you are **not** sampling (e.g. $a_{1,2}$, $D_L$, etc.). If you don't, Bilby will use their default prior, and you will spend **a lot** of time sampling. Assume that we already know the values for these parameters, what kind of distribution should their priors be?\n",
    "\n",
    "NOTE 3: To minimize the runtime, try set the prior to be as close to the true values as possible (but not too close)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Define PriorDict object\n",
    "priors = bilby.prior.PriorDict()\n",
    "\n",
    "### -------------------START-CODE-------------------- ###\n",
    "\n",
    "### -------------------END-CODE---------------------- ###\n",
    "\n",
    "priors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Next, we will set up a Gaussian noise likelihood. Unlike the previous example, writing the Gaussian likelihood for GW data can be a bit complicate, so we will use the built-in class `bilby.gw.GravitationalWaveTransient` class instead. However, it is important that you understand where this function comes from, so we ask you to write its equation down instead.\n",
    "\n",
    "You can find your answer in the lecture note or in this paper : https://arxiv.org/pdf/1809.02293.pdf (Hint: check the appendix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "#### Answer:\n",
    "Remember to explain all your variables.\n",
    "\\begin{equation}\n",
    "    \\mathcal{L(d|\\theta)} = \n",
    "\\end{equation}\n",
    "where $d$ is the GW strain and $\\theta$ is a set of GW parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Initialise the likelihood by passing in the interferometer data (ifos) and\n",
    "# the waveform generator\n",
    "likelihood = bilby.gw.GravitationalWaveTransient(\n",
    "    interferometers=ifos, waveform_generator=waveform_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to run the sampler. Again, we will use `dynesty`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "result = bilby.run_sampler(\n",
    "    likelihood=likelihood, priors=priors, sampler='dynesty', npoints=1000, \n",
    "    resume=True, outdir='GW_PEInjection_result', label='2_parameters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Similarly as in the previous example, once you obtain your sampling result, please plot the corner plot of the two component masses $M_1$ and $M_2$ of the BBH. Note that these are **not** the same parameters you have been sampling (which are the chirp mass and mass ratio), so you will to do some conversion on your posterior samples. You might find the chirp mass $M_c$ and mass ratio $q$ expressions below useful:\n",
    "\n",
    "\\begin{equation}\n",
    "M_c = \\frac{(M_1 M_2)^{3/5}}{(M_1 + M_2)^{1/5}}\\; \\text{and} \\; q=\\frac{M_2}{M_1}\n",
    "\\end{equation}\n",
    "\n",
    "What are the final values of the component masses $M_1$, $M_2$ of the BBH? Please include error bars and any neccessary statistics. How are these values compared to the true injection values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# First, we want to extract the posterior samples from bilby.result\n",
    "samples = result.posterior[['chirp_mass', 'mass_ratio']].values\n",
    "\n",
    "### -------------------START-CODE-------------------- ###\n",
    "\n",
    "### -------------------END-CODE---------------------- ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "#### Answer:\n",
    "The final values of the component masses $M_1$, $M_2$ of the BBH are:\n",
    "\\begin{equation}\n",
    "M_1 = \\;\\text{and}\\; M_2 = \n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "Congratulations! You have reached the end of the tutorial. Parameter estimation is a tough problem in gravitational-wave physics (and many other areas of physics) due to the intractable nature of the posterior distribution. Posterior sampling algorithms, such as MCMC and Nested Sampling, help solve this problem at a cost of long runtime. This makes it difficult to perform electromagnetic follow-up of time-sensitive GW sources like binary neutron stars. \n",
    "\n",
    "Deep learning algorithms are currently being developed to accelerate the posterior sampling process:\n",
    "\n",
    "- https://arxiv.org/abs/2010.12931\n",
    "- https://arxiv.org/abs/2002.07656\n",
    "- https://arxiv.org/abs/2008.03312\n",
    "- ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dc-prod-py36",
   "language": "python",
   "name": "dc-prod-py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
